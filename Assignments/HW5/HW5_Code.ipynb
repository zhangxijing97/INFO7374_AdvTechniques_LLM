{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d90d0d-3387-48f7-8404-1dfb787250e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with window size 3 and vector size 20\n",
      "Most similar to (Transform + 'daughter'): [('bratis', 0.8006808161735535)]\n",
      "Cluster assignments: {'yen': 1, 'yuan': 1, 'france': 0, 'brazil': 0, 'africa': 0, 'asia': 0}\n",
      "Training model with window size 3 and vector size 70\n",
      "Most similar to (Transform + 'daughter'): [('expansion', 0.45818030834198)]\n",
      "Cluster assignments: {'yen': 1, 'yuan': 1, 'france': 0, 'brazil': 1, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 3 and vector size 100\n",
      "Most similar to (Transform + 'daughter'): [('man', 0.4254422187805176)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 0, 'brazil': 0, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 3 and vector size 300\n",
      "Most similar to (Transform + 'daughter'): [('man', 0.5618419647216797)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 0, 'brazil': 0, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 7 and vector size 20\n",
      "Most similar to (Transform + 'daughter'): [('suffren', 0.7415822744369507)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 0, 'brazil': 0, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 7 and vector size 70\n",
      "Most similar to (Transform + 'daughter'): [('starsys', 0.4212087392807007)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 0, 'brazil': 0, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 7 and vector size 100\n",
      "Most similar to (Transform + 'daughter'): [('man', 0.4393777847290039)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 0, 'brazil': 0, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 7 and vector size 300\n",
      "Most similar to (Transform + 'daughter'): [('man', 0.4934195876121521)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 0, 'brazil': 0, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 13 and vector size 20\n",
      "Most similar to (Transform + 'daughter'): [('nasda', 0.7662496566772461)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 0, 'brazil': 1, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 13 and vector size 70\n",
      "Most similar to (Transform + 'daughter'): [('danbricklin', 0.43900245428085327)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 0, 'brazil': 0, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 13 and vector size 100\n",
      "Most similar to (Transform + 'daughter'): [('gribbin', 0.437030166387558)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 0, 'brazil': 0, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 13 and vector size 300\n",
      "Most similar to (Transform + 'daughter'): [('man', 0.48533961176872253)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 0, 'brazil': 0, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 25 and vector size 20\n",
      "Most similar to (Transform + 'daughter'): [('pulosari', 0.761509358882904)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 1, 'brazil': 0, 'africa': 0, 'asia': 0}\n",
      "Training model with window size 25 and vector size 70\n",
      "Most similar to (Transform + 'daughter'): [('restuccia', 0.5421460270881653)]\n",
      "Cluster assignments: {'yen': 1, 'yuan': 1, 'france': 1, 'brazil': 1, 'africa': 0, 'asia': 0}\n",
      "Training model with window size 25 and vector size 100\n",
      "Most similar to (Transform + 'daughter'): [('vitruvian', 0.4615863561630249)]\n",
      "Cluster assignments: {'yen': 0, 'yuan': 0, 'france': 0, 'brazil': 0, 'africa': 1, 'asia': 1}\n",
      "Training model with window size 25 and vector size 300\n",
      "Most similar to (Transform + 'daughter'): [('man', 0.49265456199645996)]\n",
      "Cluster assignments: {'yen': 1, 'yuan': 1, 'france': 1, 'brazil': 1, 'africa': 0, 'asia': 1}\n",
      "Best hyperparameters: Window size = 3, Vector size = 20\n",
      "Best transformation result: [('bratis', 0.8006808161735535)]\n",
      "Best cluster assignments: {'yen': 1, 'yuan': 1, 'france': 0, 'brazil': 0, 'africa': 0, 'asia': 0}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Load the text8 corpus\n",
    "corpus = api.load('text8')\n",
    "\n",
    "# Define the hyperparameter combinations\n",
    "win_sizes = [3, 7, 13, 25]\n",
    "vector_sizes = [20, 70, 100, 300]\n",
    "\n",
    "# Words to be used in the tasks\n",
    "words_to_transform = ['man', 'woman', 'daughter']\n",
    "words_to_cluster = ['yen', 'yuan', 'france', 'brazil', 'africa', 'asia']\n",
    "\n",
    "best_params = None\n",
    "best_similarity = None\n",
    "best_clusters = None\n",
    "best_transform_result = None\n",
    "\n",
    "for win_size in win_sizes:\n",
    "    for vector_size in vector_sizes:\n",
    "        print(f\"Training model with window size {win_size} and vector size {vector_size}\")\n",
    "        \n",
    "        # Train Word2Vec model\n",
    "        model = Word2Vec(sentences=corpus, window=win_size, vector_size=vector_size, min_count=1)\n",
    "        \n",
    "        # Define Transform as Embedding('man') - Embedding('woman')\n",
    "        transform = model.wv['man'] - model.wv['woman']\n",
    "        \n",
    "        # Find an embedding most similar to (Transform + Embedding('daughterâ€™))\n",
    "        transform_result = model.wv.most_similar(positive=['daughter', transform], topn=1)\n",
    "        print(f\"Most similar to (Transform + 'daughter'): {transform_result}\")\n",
    "        \n",
    "        # Cluster the following embeddings using K-means\n",
    "        embeddings = np.array([model.wv[word] for word in words_to_cluster])\n",
    "        kmeans = KMeans(n_clusters=2)\n",
    "        kmeans.fit(embeddings)\n",
    "        \n",
    "        clusters = {}\n",
    "        for i, label in enumerate(kmeans.labels_):\n",
    "            clusters[words_to_cluster[i]] = label\n",
    "        print(f\"Cluster assignments: {clusters}\")\n",
    "        \n",
    "        # Assess the results to determine the best set of hyperparameters\n",
    "        if best_similarity is None or transform_result[0][1] > best_similarity:\n",
    "            best_similarity = transform_result[0][1]\n",
    "            best_params = (win_size, vector_size)\n",
    "            best_clusters = clusters\n",
    "            best_transform_result = transform_result\n",
    "\n",
    "print(f\"Best hyperparameters: Window size = {best_params[0]}, Vector size = {best_params[1]}\")\n",
    "print(f\"Best transformation result: {best_transform_result}\")\n",
    "print(f\"Best cluster assignments: {best_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118d98ff-bb98-4513-803e-b03dded3f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector for Paris is:  [-0.19954316 -0.46359336  1.4442711  -0.53030515  0.30910125 -3.21829\n",
      " -0.80756897  1.9091936  -3.6736145   0.7791089   0.69424033  0.77002895\n",
      " -1.4870739  -0.55771106 -1.1213987  -0.13891496  0.16801234  0.37173176\n",
      " -0.79405314 -1.9095919   3.2849033  -2.4157815   0.22409369 -1.5381286\n",
      " -1.0676508  -1.7486839  -2.0391848   1.6171279  -1.0335131   3.9903588\n",
      " -0.981133   -0.3469918   1.3421159   2.2093349   0.56718886  1.3755047\n",
      "  1.8072823   0.31739727  0.08437763  1.350574    1.3138663  -1.2692137\n",
      "  0.8514873   0.9939338  -2.9037025   0.77163196  0.10107175 -0.09788461\n",
      "  3.04712    -2.8497846   2.0633981   0.98394775 -1.0383935  -1.5304278\n",
      " -1.6788906  -1.3294111   4.028691    0.73798347 -1.1571455   0.49761516\n",
      " -0.84745634  0.29187015  0.09646317  0.07188845 -0.00774641  1.7129927\n",
      "  0.20880346  0.77843153  2.0442166  -0.38502645]\n",
      "Similar to France:  [('france', 0.9999998211860657), ('spain', 0.8404896855354309), ('italy', 0.8255295753479004)]\n",
      "Similar to Paris:  [('paris', 1.0), ('vienna', 0.7800471782684326), ('munich', 0.7506881952285767)]\n",
      "Transform:  [('portugal', 0.6722958087921143), ('france', 0.6693373322486877), ('spain', 0.6551873087882996)]\n",
      "Embedding  0  is in cluster  1\n",
      "Embedding  1  is in cluster  0\n",
      "Embedding  2  is in cluster  1\n",
      "Embedding  3  is in cluster  0\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "corpus = api.load('text8')\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=corpus, window=5, vector_size=70)\n",
    "\n",
    "print(\"Embedding vector for Paris is: \", model.wv['paris'])\n",
    "\n",
    "print('Similar to France: ', model.wv.similar_by_vector (model.wv['france'],topn=3))\n",
    "print('Similar to Paris: ', model.wv.similar_by_vector (model.wv['paris'],topn=3))\n",
    "\n",
    "# Find most similar embeddings to a transformed embedding\n",
    "transform = model.wv['france'] - model.wv['paris']\n",
    "print('Transform: ', model.wv.similar_by_vector ( transform + model.wv['madrid'] ,topn=3))\n",
    "\n",
    "# Some word embeddings\n",
    "embeddings =np.array([\n",
    "model.wv['paris'] , model.wv['he'],\n",
    "model.wv['vienna'] , model.wv['she']\n",
    "])\n",
    "\n",
    "# K-means clustering\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "# Print cluster assignments\n",
    "for i, label in enumerate(kmeans.labels_):\n",
    "    print(\"Embedding \", i, \" is in cluster \", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9228d47e-71f0-45a6-9a4c-a58a4fdabbba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
