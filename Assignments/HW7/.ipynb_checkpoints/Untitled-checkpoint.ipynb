{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1590a-80bf-410a-964a-1ec8fc3ccb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070980bc0da6467399810ebd1b433083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d789429537894439b21398dd60cd45a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccf001c259845ea84820255df5a3df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc899597a85945e2ae9c93d1a3f6407c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ed146ec86349bda010311fae6854bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.09747529029846191, 'token': 10533, 'token_str': 'carpenter', 'sequence': 'the man worked as a carpenter.'}, {'score': 0.05238306522369385, 'token': 15610, 'token_str': 'waiter', 'sequence': 'the man worked as a waiter.'}, {'score': 0.04962717741727829, 'token': 13362, 'token_str': 'barber', 'sequence': 'the man worked as a barber.'}, {'score': 0.03788601607084274, 'token': 15893, 'token_str': 'mechanic', 'sequence': 'the man worked as a mechanic.'}, {'score': 0.0376807376742363, 'token': 18968, 'token_str': 'salesman', 'sequence': 'the man worked as a salesman.'}]\n",
      "[{'score': 0.21981723606586456, 'token': 6821, 'token_str': 'nurse', 'sequence': 'the woman worked as a nurse.'}, {'score': 0.15974149107933044, 'token': 13877, 'token_str': 'waitress', 'sequence': 'the woman worked as a waitress.'}, {'score': 0.11547167599201202, 'token': 10850, 'token_str': 'maid', 'sequence': 'the woman worked as a maid.'}, {'score': 0.03796853497624397, 'token': 19215, 'token_str': 'prostitute', 'sequence': 'the woman worked as a prostitute.'}, {'score': 0.03042353130877018, 'token': 5660, 'token_str': 'cook', 'sequence': 'the woman worked as a cook.'}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a75c6a3b8124c9dbde1b8300293c020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8dd30f2b3047c79c4e85ec166d841a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4ab066b7a94170a9d1b2feb5bec672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb4ff366e2d42b4a386ab1e48b0827d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9997925162315369}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504fe4f575424f57b144596432f91d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf98d90774a64717ab71c827d14e0fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1377d5538f745f9a90c80caf6e2f41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/309 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480de7dd49554b08ae92bc0fe700446b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc74a5c401ef4fa88962e22d85acde3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c58899f19944e64b3887e81bc9e8dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d3c51758fe426f879f4c915b55e018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this article, we look at some of the most striking examples of how machines have changed the way we work.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ada7458d2a24eda9a8a5b18abd59ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c823764a6d9344bf96a80afbc69656e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "print(unmasker(\"The man worked as a [MASK].\"))\n",
    "print(unmasker(\"The woman worked as a [MASK].\"))\n",
    "\n",
    "\n",
    "analyze_sentiment = pipeline('text-classification',model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "print(analyze_sentiment(\"The movie was bad\"))\n",
    "\n",
    "\n",
    "summarize = pipeline('summarization', model='facebook/bart-large-xsum')\n",
    "text = summarize(\"\"\"Machine has displaced human labour in today's factories and workshops.\n",
    "                           Machines have mostly taken over tasks that were once performed by hand.\n",
    "                           Machines has mostly supplanted human workers in telemarketing and customer support\"\"\",\n",
    "                 min_length=5, max_length=40, do_sample=False)\n",
    "print(text[0]['summary_text'])\n",
    "\n",
    "\n",
    "translate = pipeline('translation_en_to_fr', model='google-t5/t5-base')\n",
    "text= translate(\" BART is able to handle a range of NLP challenges effectively\")\n",
    "print(text[0]['translation_text'])\n",
    "\n",
    "translate = pipeline('translation', src_lang='fr',tgt_lang='en',model='facebook/m2m100_418M')\n",
    "text= translate(text[0]['translation_text'])\n",
    "print(text[0]['translation_text'])\n",
    "\n",
    "print('test')\n",
    "\n",
    "\n",
    "# from openai import OpenAI\n",
    "\n",
    "# key= '' #get a key from: https://platform.openai.com/api-keys\n",
    "# query = 'complete the following scentence with one word. just give me three names of most probable words: this is a nice'\n",
    "# client = OpenAI(api_key=key)\n",
    "# completion = client.chat.completions.create(\n",
    "#             model='gpt-4o',\n",
    "#             messages=[{\"role\": \"user\", \"content\": query}],\n",
    "#             logprobs=True,\n",
    "#             temperature= 1,\n",
    "#         )\n",
    "# print(completion.choices[0].message.content)\n",
    "# print(completion.choices[0].logprobs.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a6d0fd-daa5-4a25-9ff6-5d343cde610c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
